{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b4344c6a-5b27-4783-8c0e-55dfe5c6bf3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b4007310-b2af-46a0-800a-e0700ea3baa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt=pd.read_csv(r'filtered_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab3efe59-0f1f-4fe7-9213-c01590705e9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>label</th>\n",
       "      <th>chest_ACC_x</th>\n",
       "      <th>chest_ACC_y</th>\n",
       "      <th>chest_ACC_z</th>\n",
       "      <th>chest_ECG</th>\n",
       "      <th>chest_EMG</th>\n",
       "      <th>chest_EDA</th>\n",
       "      <th>chest_Temp</th>\n",
       "      <th>chest_Resp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9554</td>\n",
       "      <td>-0.2220</td>\n",
       "      <td>-0.5580</td>\n",
       "      <td>0.021423</td>\n",
       "      <td>-0.004440</td>\n",
       "      <td>5.250549</td>\n",
       "      <td>30.120758</td>\n",
       "      <td>-1.148987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9258</td>\n",
       "      <td>-0.2216</td>\n",
       "      <td>-0.5538</td>\n",
       "      <td>0.020325</td>\n",
       "      <td>0.004349</td>\n",
       "      <td>5.267334</td>\n",
       "      <td>30.129517</td>\n",
       "      <td>-1.124573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9082</td>\n",
       "      <td>-0.2196</td>\n",
       "      <td>-0.5392</td>\n",
       "      <td>0.016525</td>\n",
       "      <td>0.005173</td>\n",
       "      <td>5.243301</td>\n",
       "      <td>30.138214</td>\n",
       "      <td>-1.152039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8974</td>\n",
       "      <td>-0.2102</td>\n",
       "      <td>-0.5122</td>\n",
       "      <td>0.016708</td>\n",
       "      <td>0.007187</td>\n",
       "      <td>5.249405</td>\n",
       "      <td>30.129517</td>\n",
       "      <td>-1.158142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8882</td>\n",
       "      <td>-0.2036</td>\n",
       "      <td>-0.4824</td>\n",
       "      <td>0.011673</td>\n",
       "      <td>-0.015152</td>\n",
       "      <td>5.286407</td>\n",
       "      <td>30.130950</td>\n",
       "      <td>-1.161194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subject_id  label  chest_ACC_x  chest_ACC_y  chest_ACC_z  chest_ECG  \\\n",
       "0         S2      0       0.9554      -0.2220      -0.5580   0.021423   \n",
       "1         S2      0       0.9258      -0.2216      -0.5538   0.020325   \n",
       "2         S2      0       0.9082      -0.2196      -0.5392   0.016525   \n",
       "3         S2      0       0.8974      -0.2102      -0.5122   0.016708   \n",
       "4         S2      0       0.8882      -0.2036      -0.4824   0.011673   \n",
       "\n",
       "   chest_EMG  chest_EDA  chest_Temp  chest_Resp  \n",
       "0  -0.004440   5.250549   30.120758   -1.148987  \n",
       "1   0.004349   5.267334   30.129517   -1.124573  \n",
       "2   0.005173   5.243301   30.138214   -1.152039  \n",
       "3   0.007187   5.249405   30.129517   -1.158142  \n",
       "4  -0.015152   5.286407   30.130950   -1.161194  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7f35f3a-2753-4153-9022-6ce17b83e646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5128356 entries, 0 to 5128355\n",
      "Data columns (total 10 columns):\n",
      " #   Column       Dtype  \n",
      "---  ------       -----  \n",
      " 0   subject_id   object \n",
      " 1   label        int64  \n",
      " 2   chest_ACC_x  float64\n",
      " 3   chest_ACC_y  float64\n",
      " 4   chest_ACC_z  float64\n",
      " 5   chest_ECG    float64\n",
      " 6   chest_EMG    float64\n",
      " 7   chest_EDA    float64\n",
      " 8   chest_Temp   float64\n",
      " 9   chest_Resp   float64\n",
      "dtypes: float64(8), int64(1), object(1)\n",
      "memory usage: 391.3+ MB\n"
     ]
    }
   ],
   "source": [
    "dt.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38222db9-7be1-41de-a4de-3404df11e114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5128356, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b208cb6-1b82-4df7-94e0-4c0b814ec075",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "176d8a23-c934-43ef-a542-10d8574425de",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = dt[['chest_ACC_x', 'chest_ACC_y', 'chest_ACC_z', 'chest_ECG', 'chest_EMG', 'chest_EDA', 'chest_Temp', 'chest_Resp']]\n",
    "target = dt['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bd49ebaf-3ea5-4931-86b4-708537938e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to tensors\n",
    "features_tensor = torch.tensor(features.values, dtype=torch.float32)\n",
    "target_tensor = torch.tensor(target.values, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "10c56c3a-31de-46e9-90a2-6bfe824450ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features_tensor, target_tensor, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5b61c443-8fab-407d-b8e7-b2334f6fbd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PyTorch datasets\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a19e0f4a-e762-4ba2-a88c-992d8a81c4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoader for batch processing\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47737340-a8bc-407f-b6fd-23b08ecd8461",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # LSTM expects input of shape (batch_size, sequence_length, input_size)\n",
    "        x = x.unsqueeze(1)  # Add a sequence length of 1\n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.fc(out[:, -1, :])  # Use the last output for classification\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0425b7e9-e295-4cf8-81b4-6b2fe13f7123",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(AttentionModel, self).__init__()\n",
    "        self.attention = nn.Linear(hidden_size, 1)\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Apply first linear layer\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        # Compute attention weights\n",
    "        attention_weights = torch.softmax(self.attention(x), dim=1)\n",
    "        # Apply attention weights\n",
    "        x = (attention_weights * x).sum(dim=1)\n",
    "        return self.fc2(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7e63b9f2-c807-453c-b89d-f32c34e60e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Transformer\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_size, num_heads, hidden_size, output_size, num_layers=2):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.transformer = Transformer(d_model=input_size, nhead=num_heads, num_encoder_layers=num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(input_size, output_size)  # Final fully connected layer for classification\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Transformer requires a 3D input tensor of shape (batch_size, sequence_length, input_size)\n",
    "        x = self.transformer(x, x)  # Using same tensor as input and target to simplify\n",
    "        x = x.mean(dim=1)  # Pooling, take the mean across the sequence dimension\n",
    "        return self.fc(x)  # Apply final fully connected layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "16840de8-e603-46b7-bda6-d13ef65b41b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "def train_model(model, train_loader, test_loader, num_epochs=5, learning_rate=0.001):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        # Evaluate the model\n",
    "        model.eval()\n",
    "        correct, total = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in test_loader:\n",
    "                outputs = model(X_batch)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += y_batch.size(0)\n",
    "                correct += (predicted == y_batch).sum().item()\n",
    "        \n",
    "        accuracy = 100 * correct / total\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/10000:.4f}, Accuracy: {accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "55caaf11-0ba6-4cbb-a6d3-ea671da301f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 10472.0328, Accuracy: 96.34%\n",
      "Epoch [2/5], Loss: 5775.6879, Accuracy: 96.87%\n",
      "Epoch [3/5], Loss: 4714.0968, Accuracy: 97.56%\n",
      "Epoch [4/5], Loss: 4154.9206, Accuracy: 97.21%\n",
      "Epoch [5/5], Loss: 3788.4870, Accuracy: 97.92%\n"
     ]
    }
   ],
   "source": [
    "input_size = features.shape[1]\n",
    "hidden_size = 128\n",
    "num_layers = 2\n",
    "output_size = len(target.unique())  # Number of unique labels\n",
    "\n",
    "lstm_model = LSTMModel(input_size, hidden_size, num_layers, output_size)\n",
    "train_model(lstm_model, train_loader, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba53ba79-e0dd-472e-b055-51d54afd968c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f294d61-c34f-4a3f-bddf-76e2443c31a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46477a93-dcc5-4af2-9a06-25e5a054494e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 1.8294, Accuracy: 94.44%\n",
      "Epoch [2/5], Loss: 1.3374, Accuracy: 93.75%\n",
      "Epoch [3/5], Loss: 1.2005, Accuracy: 95.62%\n",
      "Epoch [4/5], Loss: 1.1075, Accuracy: 95.77%\n",
      "Epoch [5/5], Loss: 1.0469, Accuracy: 95.70%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "\n",
    "\n",
    "class AttentionModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(AttentionModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)  # LSTM layer\n",
    "        self.fc1 = nn.Linear(hidden_size, hidden_size)  # Second hidden layer\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)  # Output layer\n",
    "        self.dropout = nn.Dropout(p=0.5)  # Dropout layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)  # Add sequence dimension\n",
    "        x, _ = self.lstm(x)  # Pass through LSTM\n",
    "        x = x[:, -1, :]  # Get last output from LSTM\n",
    "        x = torch.relu(self.fc1(x))  # First layer with ReLU activation\n",
    "        x = self.dropout(x)  # Apply dropout\n",
    "        return self.fc2(x)  # Output layer\n",
    "\n",
    "\n",
    "    def calculate_attention_weights(self, x):\n",
    "        # Scaled dot-product attention example\n",
    "        attention_scores = torch.matmul(x, x.transpose(1, 2)) / (x.size(-1) ** 0.5)\n",
    "        attention_weights = torch.softmax(attention_scores, dim=-1)\n",
    "        return attention_weights\n",
    "\n",
    "# Instantiate the model\n",
    "input_size = features.shape[1]  # Number of input features (8)\n",
    "hidden_size = 64  # Hidden size (you can adjust this)\n",
    "output_size = len(target.unique())  # Number of unique labels (5)\n",
    "\n",
    "Attention_Model = AttentionModel(input_size, hidden_size, output_size,)\n",
    "\n",
    "\n",
    "# Run the training\n",
    "train_model(Attention_Model, train_loader, test_loader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8322119f-b0dc-4b98-b0d3-a762ac7e8280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 2.6155, Accuracy: 93.26%\n",
      "Epoch [2/5], Loss: 1.2928, Accuracy: 94.99%\n",
      "Epoch [3/5], Loss: 1.1116, Accuracy: 95.24%\n",
      "Epoch [4/5], Loss: 1.0207, Accuracy: 95.22%\n",
      "Epoch [5/5], Loss: 0.9559, Accuracy: 95.19%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class EnhancedAttentionModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(EnhancedAttentionModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers=2, batch_first=True, dropout=0.3)  # Double LSTM layers\n",
    "        self.attention_fc = nn.Linear(hidden_size, hidden_size)  # For attention mechanism\n",
    "        self.fc1 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)  # Add sequence dimension\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        attention_weights = torch.softmax(self.attention_fc(lstm_out[:, -1, :]), dim=1)  # Attention on LSTM output\n",
    "        x = attention_weights * lstm_out[:, -1, :]  # Weighted sum\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        return self.fc2(x)\n",
    "\n",
    "\n",
    "\n",
    "    def calculate_attention_weights(self, x):\n",
    "        # Scaled dot-product attention example\n",
    "        attention_scores = torch.matmul(x, x.transpose(1, 2)) / (x.size(-1) ** 0.5)\n",
    "        attention_weights = torch.softmax(attention_scores, dim=-1)\n",
    "        return attention_weights\n",
    "\n",
    "# Instantiate the model\n",
    "input_size = features.shape[1]  # Number of input features (8)\n",
    "hidden_size = 64  # Hidden size (you can adjust this)\n",
    "output_size = len(target.unique())  # Number of unique labels (5)\n",
    "\n",
    "Attention_Model = EnhancedAttentionModel(input_size, hidden_size, output_size,)\n",
    "\n",
    "\n",
    "# Run the training\n",
    "train_model(Attention_Model, train_loader, test_loader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "208bd4e2-df57-4b33-8ded-a59a74a451b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdvancedTransformerModel(\n",
      "  (embedding): Linear(in_features=8, out_features=128, bias=True)\n",
      "  (pos_encoder): PositionalEncoding()\n",
      "  (transformer): Transformer(\n",
      "    (encoder): TransformerEncoder(\n",
      "      (layers): ModuleList(\n",
      "        (0-2): 3 x TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.3, inplace=False)\n",
      "          (linear2): Linear(in_features=512, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.3, inplace=False)\n",
      "          (dropout2): Dropout(p=0.3, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (decoder): TransformerDecoder(\n",
      "      (layers): ModuleList(\n",
      "        (0-2): 3 x TransformerDecoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (multihead_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.3, inplace=False)\n",
      "          (linear2): Linear(in_features=512, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.3, inplace=False)\n",
      "          (dropout2): Dropout(p=0.3, inplace=False)\n",
      "          (dropout3): Dropout(p=0.3, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=128, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "from torch.nn import Transformer\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:x.size(0), :]\n",
    "\n",
    "class AdvancedTransformerModel(nn.Module):\n",
    "    def __init__(self, input_size, num_heads, hidden_size, output_size, num_layers=2, dropout=0.1):\n",
    "        super(AdvancedTransformerModel, self).__init__()\n",
    "        self.embedding = nn.Linear(input_size, hidden_size)  # Embedding layer to project input\n",
    "        self.pos_encoder = PositionalEncoding(hidden_size)  # Positional encoding\n",
    "        self.transformer = Transformer(\n",
    "            d_model=hidden_size,\n",
    "            nhead=num_heads,\n",
    "            num_encoder_layers=num_layers,\n",
    "            num_decoder_layers=num_layers,\n",
    "            dim_feedforward=hidden_size * 4,\n",
    "            dropout=dropout,\n",
    "            batch_first=True  # Ensures compatibility with batch dimension\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_size, output_size)  # Classification head\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.layer_norm = nn.LayerNorm(hidden_size)  # Normalization layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Embedding\n",
    "        x = self.embedding(x)\n",
    "        x = self.pos_encoder(x)  # Add positional encoding\n",
    "        \n",
    "        # Transformer Encoder\n",
    "        x = self.transformer(x, x)  # Self-attention applied here\n",
    "        \n",
    "        # Pooling: Take the mean of the sequence for classification\n",
    "        x = x.mean(dim=1)  # Mean pooling across sequence length\n",
    "\n",
    "        # Final layers\n",
    "        x = self.layer_norm(x)  # Layer normalization\n",
    "        x = self.dropout(x)     # Dropout for regularization\n",
    "        return self.fc(x)       # Classification output\n",
    "\n",
    "# Instantiate the model with parameters\n",
    "input_size = 8  # Number of input features\n",
    "num_heads = 4  # Number of attention heads\n",
    "hidden_size = 128  # Hidden size for embedding and transformer layers\n",
    "output_size = 5  # Number of output classes\n",
    "num_layers = 3  # Number of transformer layers\n",
    "dropout = 0.3  # Dropout rate\n",
    "\n",
    "model = AdvancedTransformerModel(input_size, num_heads, hidden_size, output_size, num_layers, dropout)\n",
    "\n",
    "# Print the model to inspect architecture\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8e43269f-0a5f-4a6f-a6a0-1ceb7ca55918",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Run the training\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[9], line 13\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, train_loader, test_loader, num_epochs, learning_rate)\u001b[0m\n\u001b[0;32m     11\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(X_batch)\n\u001b[0;32m     12\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, y_batch)\n\u001b[1;32m---> 13\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     15\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    580\u001b[0m     )\n\u001b[1;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\autograd\\graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Run the training\n",
    "train_model(model, train_loader, test_loader, num_epochs=5, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "89f4b614-29f3-431d-86c6-c76ff6f83957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 0.3052, Accuracy: 87.74%\n",
      "Test Accuracy after epoch 1: 93.06%\n",
      "\n",
      "Epoch [2/5], Loss: 0.1757, Accuracy: 93.51%\n",
      "Test Accuracy after epoch 2: 95.15%\n",
      "\n",
      "Epoch [3/5], Loss: 0.1568, Accuracy: 94.23%\n",
      "Test Accuracy after epoch 3: 95.76%\n",
      "\n",
      "Epoch [4/5], Loss: 0.1351, Accuracy: 95.05%\n",
      "Test Accuracy after epoch 4: 95.40%\n",
      "\n",
      "Epoch [5/5], Loss: 0.1205, Accuracy: 95.55%\n",
      "Test Accuracy after epoch 5: 96.19%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import Transformer\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_size, num_heads, hidden_size, output_size, num_layers=2):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        \n",
    "        self.input_fc = nn.Linear(input_size, hidden_size)  # Project input to hidden size\n",
    "        self.transformer = Transformer(d_model=hidden_size, nhead=num_heads, num_encoder_layers=num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)  # Final output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [batch_size, seq_len, input_size]\n",
    "        x = x.unsqueeze(1)  # Add sequence length dimension: [batch_size, seq_len=1, input_size]\n",
    "        x = self.input_fc(x)  # [batch_size, seq_len=1, hidden_size]\n",
    "        x = self.transformer(x, x)  # Pass through Transformer\n",
    "        \n",
    "        # Use the last output of the sequence\n",
    "        x = x[:, -1, :]  # Take the last output for classification: [batch_size, hidden_size]\n",
    "        \n",
    "        return self.fc(x)  # [batch_size, output_size]\n",
    "\n",
    "# Training function remains the same\n",
    "def train_model(model, train_loader, test_loader, num_epochs=5, learning_rate=0.001):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.float(), labels.long()  # Ensure correct types\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)  # Expected shape: [batch_size, output_size]\n",
    "\n",
    "            # Debugging shapes\n",
    "            #print(f\"Inputs shape: {inputs.shape}, Outputs shape: {outputs.shape}, Labels shape: {labels.shape}\")\n",
    "\n",
    "            # Ensure the shapes match for the loss calculation\n",
    "            assert outputs.shape[0] == labels.shape[0], \"Output and labels batch sizes do not match!\"\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        train_accuracy = 100 * correct / total\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}, Accuracy: {train_accuracy:.2f}%\")\n",
    "        \n",
    "        # Evaluate on test set after each epoch\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_loader:\n",
    "                inputs, labels = inputs.float(), labels.long()\n",
    "                outputs = model(inputs)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        test_accuracy = 100 * correct / total\n",
    "        print(f\"Test Accuracy after epoch {epoch+1}: {test_accuracy:.2f}%\\n\")\n",
    "\n",
    "# Model and training parameters\n",
    "input_size = 8       # Number of input features\n",
    "num_heads = 4        # Number of attention heads\n",
    "hidden_size = 64     # Hidden size for embedding and transformer layers\n",
    "output_size = 5      # Number of output classes\n",
    "num_layers = 2       # Number of transformer layers\n",
    "\n",
    "# Initialize and train the model\n",
    "model = TransformerModel(input_size, num_heads, hidden_size, output_size, num_layers)\n",
    "train_model(model, train_loader, test_loader, num_epochs=5, learning_rate=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a98889-ca01-4ab4-92c7-26c1b07801a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
